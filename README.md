# SAMPro3D-trial

> **3D point cloud processing is often computationally expensive.**  
> This repository contains my customized implementation of **SAMPro3D** for efficient and flexible 3D instance segmentation experiments.


https://github.com/user-attachments/assets/1b519fda-18f4-4163-9f64-f5433003dbbc


---

## ğŸ“„ Original Paper  
**SAMPro3D: Locating SAM Prompts in 3D for Zero-Shot Instance Segmentation**  
ğŸ”— [Mutian Xu et al. â€“ Official Project Page](https://mutianxu.github.io/sampro3d/)

---

## ğŸ“‚ Repository Structure
```

SAMPro3D-trial/
â”œâ”€â”€ room.ply                  # Example 3D point cloud input
â”œâ”€â”€ room.xyz                  # Scene point cloud for matching
â”œâ”€â”€ rgb_images/               # Captured RGB images (auto-created by the script)
â”œâ”€â”€ depth_images/             # Captured depth images (auto-created by the script)
â”œâ”€â”€ params/                   # Saved camera parameters (auto-created by the script)
â”œâ”€â”€ saved_images/             # 2D projection plots (auto-created by the script)
â”œâ”€â”€ sam2_hiera_l.yaml         # Configuration files for SAM2
â”œâ”€â”€ sam2_hiera_large.pt       # Pre-trained SAM2 weights
â”œâ”€â”€ main.py     # Main script containing all processing steps and functions
â”œâ”€â”€ requirements.txt          # Dependencies list
â””â”€â”€ README.md                 # Project documentation

````

---

## ğŸš€ Usage Instructions

### 1ï¸âƒ£ **Installation**
Clone the repository and install dependencies:
```bash
git clone https://github.com/your-username/SAMPro3D-trial.git
cd SAMPro3D-trial
pip install -r requirements.txt
````

---

### 2ï¸âƒ£ **Prepare Your Data**

* Place your **input point cloud** (e.g., `room.ply`) and **scene cloud** (`room.xyz`) inside the `data/` folder.
* Ensure you have the SAM2 **checkpoint** (`sam2_hiera_large.pt`) and **config** (`sam2_hiera_l.yaml`) in the appropriate folders (`checkpoints/` and `configs/`).

---

### 3ï¸âƒ£ **Run the Pipeline**

Execute the main script:

```bash
python src/sampro3d_trial.py
```

---

### 4ï¸âƒ£ **Interactive Steps**

1. **Pick Points**

   * The Open3D visualizer opens.
   * Select **foreground points** (`shift + left-click`) inside the desired area, then press **Q**.
   * Repeat for **background points**.

2. **Capture Images**

   * The script will rotate the scene and capture **RGB** and **depth images** automatically.
   * Camera parameters will be saved as JSON in the `params/` folder.

3. **Segmentation & Mask Filtering**

   * SAM2 is applied to segment the object based on selected points.
   * Masks are filtered and overlaid on the RGB images for verification.

4. **Point Reprojection and Matching**

   * 2D points are reprojected back to 3D.
   * Matched points between the instance and scene clouds are filtered using `cKDTree`.

5. **Mesh Generation**

   * High-accuracy meshes are generated using Poisson reconstruction.
   * Smaller disconnected parts are removed, keeping only the largest connected component.

6. **Combine Results**

   * All matched point clouds are merged and saved as `combined_matched_original_pcd.ply`.

---

### 5ï¸âƒ£ **Output**

* âœ… **Matched Point Clouds**: `matched_original_pcd_*.ply`
* âœ… **Combined Point Cloud**: `combined_matched_original_pcd.ply`
* âœ… **Filtered Masks & Overlays**: Saved in `saved_images/`
* âœ… **Captured Data**: RGB, depth, and parameters saved automatically

---

### ğŸ§° **Key Libraries Used**

* [Open3D](http://www.open3d.org/) â€“ Point cloud visualization and processing
* [PyTorch](https://pytorch.org/) â€“ Tensor computations and GPU acceleration
* [SciPy](https://scipy.org/) (`cKDTree`) â€“ Fast nearest neighbor search
* [OpenCV](https://opencv.org/) â€“ Image and contour operations
* [Matplotlib](https://matplotlib.org/) â€“ Visualization
* [Pandas](https://pandas.pydata.org/) â€“ Correlation and data analysis
* [SAM2](https://github.com/mutianxu/SAMPro3D) â€“ Image segmentation backbone
